{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2342813f",
   "metadata": {},
   "source": [
    "## Student Name: \n",
    "## Student Email:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6ab65",
   "metadata": {},
   "source": [
    "# Project 3: The Smart City Slicker\n",
    "\n",
    "Imagine you are a stakeholder in a rising Smart City and want to know more about themes and concepts about existing smart cities. You also want to know where does your smart city place among others. In this project, you will perform \n",
    "exploratory data analysis, often shortened to EDA, to examine a data from the [2015 Smart City Challenge](https://www.transportation.gov/smartcity) to find facts about the data and communicating those facts through text analysis and visualizations.\n",
    "\n",
    "In order to explore the data and visualize it, some modifications might need to be made to the data along the way. This is often referred to as data preprocessing or cleaning.\n",
    "Though data preprocessing is technically different from EDA, EDA often exposes problems with the data that need to be fixed in order to continue exploring.\n",
    "Because of this tight coupling, you have to clean the data as necessary to help understand the data.\n",
    "\n",
    "In this project, you will apply your knowledge about data cleaning, machine learning, visualizations, and databases to explore smart city applications.\n",
    "\n",
    "**Part 1** of the notebook will explore and clean the data. \\\n",
    "**Part 2** will take the results of the preprocessed data to create models and visualizations.\n",
    "\n",
    "Empty cells are code cells. \n",
    "Cells denoted with [Your Answer Here] are markdown cells.\n",
    "Edit and add as many cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dcba1",
   "metadata": {},
   "source": [
    "Output file for this notebook is shown as a table for display purposes. Note: The city name can be Norman, OK or OK Norman.\n",
    "\n",
    "| city | raw text | clean text | clusterid | topicids | \n",
    "| -- | -- | -- | -- | -- | \n",
    "|Norman, OK | Test, test , and testing. | test test test | 0 | T1, T2| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd47ce",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The Dataset: 2015 Smart City Challenge Applicants (non-finalist).\n",
    "In this project you will use the applicant's PDFs as a dataset.\n",
    "The dataset is from the U.S Department of Transportation Smart City Challenge.\n",
    "\n",
    "On the website page for the data, you can find some basic information about the challenge. This is an interesting dataset. Think of the questions that you might be able to answer! A few could be:\n",
    "\n",
    "1. Can I identify frequently occurring words that could be removed during data preprocessing?\n",
    "2. Where are the applicants from?\n",
    "3. Are there multiple entries for the same city in different applicantions?\n",
    "4. What are the major themes and concepts from the smart city applicants?\n",
    "\n",
    "Let's load the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aace966",
   "metadata": {},
   "source": [
    "## Loading and Handling files (Required)\n",
    "\n",
    "Load data from `smartcity/`. \n",
    "\n",
    "To extract the data from the pdf files, use the [pypdf.pdf.PdfFileReader](https://pypdf.readthedocs.io/en/stable/index.html) class.\n",
    "It will allow you to extract pages and pdf files and add them to a data structure (dataframe, list, dictionary, etc).\n",
    "To install the module, use the command `pipenv install pypdf`.\n",
    "You only need to handle PDF files, handling docx is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0afb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AK Anchorage.pdf', 'AL Birmingham.pdf', 'AL Montgomery.pdf', 'AZ Scottsdale AZ.pdf', 'AZ Tucson.pdf', 'CA Chula Vista.pdf', 'CA Fremont.pdf', 'CA Fresno.pdf', 'CA Long Beach.pdf', 'CA Oakland.pdf', 'CA Oceanside.pdf', 'CA Riverside.pdf', 'CA Sacramento.pdf', 'CA San Jose_0.pdf', 'CT NewHaven.pdf', 'DC_0.pdf', 'FL Jacksonville.pdf', 'FL Miami.pdf', 'FL Orlando.pdf', 'FL St. Petersburg.pdf', 'FL Tampa.pdf', 'GA Atlanta.pdf', 'GA Brookhaven.pdf', 'IA Des Moines.pdf', 'IN Indianapolis.pdf', 'KY Louisville.pdf', 'LA Baton Rouge.pdf', 'LA New Orleans.pdf', 'LA Shreveport.pdf', 'MA Boston.pdf', 'MD Baltimore.pdf', 'MI Detroit.pdf', 'MI Port Huron and Marysville.pdf', 'MN Minneapolis St Paul.pdf', 'MO St. Louis.pdf', 'NC Charlotte.pdf', 'NC Greensboro.pdf', 'NC Raleigh.pdf', 'NE Lincoln.pdf', 'NE Omaha.pdf', 'NJ Jersey City.pdf', 'NJ Newark.pdf', 'NV Las Vegas.pdf', 'NY Albany Troy Schenectady Saratoga Springs.pdf', 'NY Buffalo.pdf', 'NY Mt Vernon Yonkers New Rochelle.pdf', 'NY Rochester.pdf', 'OH Akron.pdf', 'OH Canton.pdf', 'OH Cleveland.pdf', 'OK Oklahoma City.pdf', 'OK Tulsa.pdf', 'RI Providence.pdf', 'SC Greenville.pdf', 'TN Chattanooga.pdf', 'TN Memphis.pdf', 'TN Nashville.pdf', 'VA Newport News.pdf', 'VA Norfolk.pdf', 'VA Richmond.pdf', 'VA Virginia Beach.pdf', 'WA Seattle.pdf', 'WA Spokane.pdf', 'WI Madison.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from project3 import *\n",
    "\n",
    "\n",
    "path = os.path.abspath('./smartcity')\n",
    "remove_cities = ['CA Moreno Valley', 'FL Tallahassee', 'NV Reno', 'OH Toledo', 'TX Lubbock']\n",
    "filenames = [filename for filename in os.listdir(path) if filename.endswith('.pdf') and filename[:len(filename) - 4] not in remove_cities]\n",
    "\n",
    "\n",
    "print(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc44b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datas = {}\n",
    "for filename in filenames:\n",
    "    file_path = os.path.join(path, filename)\n",
    "    city = filename[:len(filename) - 4]\n",
    "    _, raw_data = get_raw_data(file_path)\n",
    "    raw_datas[city] = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed6e32",
   "metadata": {},
   "source": [
    "Create a data structure to add the city name and raw text. You can choose to split the city name from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e4905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "df['city'] = np.array([filename[:len(filename) - 4] for filename in filenames])\n",
    "df['raw text'] = df['city'].apply(lambda x : raw_datas[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019a8c3",
   "metadata": {},
   "source": [
    "## Cleaning Up PDFs (Required)\n",
    "\n",
    "One of the more frustrating aspects of PDF is loading the data into a readable format. The first order of business will be to preprocess the data. To start, you can use code provided by Text Analytics with Python, [Chapter 3](https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch03%20-%20Processing%20and%20Understanding%20Text/Ch03a%20-%20Text%20Wrangling.ipynb): [contractions.py](https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch05%20-%20Text%20Classification/contractions.py) (Pages 136-137), and [text_normalizer.py](https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch05%20-%20Text%20Classification/text_normalizer.py) (Pages 155-156). Feel free to download the scripts or add the code directly to the notebook (please note this code is performed on dataframes).\n",
    "\n",
    "In addition to the data cleaning provided by the textbook, you will need to:\n",
    "1. Consider removing terms that may effect clustering and topic modeling. Words to consider are cities, states, common words (smart, city, page, etc.). Keep in mind n-gram combinations are important; this can also be revisited later depending on your model's performance.\n",
    "2. Check the data to remove applicants that text was not processed correctly. Do not remove more than 15 cities from the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473a3e3",
   "metadata": {},
   "source": [
    "#### Add the cleaned text to the structure you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3737fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean text'] = df['raw text'].apply(lambda x : data_clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc947b",
   "metadata": {},
   "source": [
    "### Clean Up: Discussion\n",
    "Answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ba98d",
   "metadata": {},
   "source": [
    "#### Which Smart City applicants did you remove? What issues did you see with the documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebf5a5",
   "metadata": {},
   "source": [
    "[Your Answer Here]['CA Moreno Valley', 'FL Tallahassee', 'NV Reno', 'OH Toledo', 'TX Lubbock'], when we process the pdf data, the processed result is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620ed74",
   "metadata": {},
   "source": [
    "#### Explain what additional text processing methods you used and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42fc81",
   "metadata": {},
   "source": [
    "[Your Answer Here]replace word in common_words = ['Smart City', 'City', 'city', 'page', 'Page', 'challenge', 'challenges', \"The City's\", 'The City'] with M, as they are all noun and they are common in all pdfs.(I want to use this previously, but the previous method is too time consuming, so I discard it, but I preserve this as a point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15817355",
   "metadata": {},
   "source": [
    "#### Did you identify any potientally problematic words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad6082",
   "metadata": {},
   "source": [
    "[Your Answer Here]Maybe some words like the, 's will be problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1507fbe",
   "metadata": {},
   "source": [
    "## Experimenting with Clustering Models (Required)\n",
    "\n",
    "Now, you'll start to explore models to find the optimal clustering model. In this section, you'll explore [K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), [Hierarchical](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html), and [DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN) clustering algorithms.\n",
    "Create these algorithms with k_clusters for K-means and Hierarchical.\n",
    "For each cell in the table provide the [Silhouette score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score), [Calinski and Harabasz score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html#sklearn.metrics.calinski_harabasz_score), and [Davies-Bouldin score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html#sklearn.metrics.davies_bouldin_score).\n",
    "\n",
    "In each cell, create an array to store the values.\n",
    "For example, \n",
    "\n",
    "|Algorithm| k = 9 | k = 18| k = 36 | Optimal k| \n",
    "|--|--|--|--|--|\n",
    "|K-means| [S,CH,DB]| [S,CH,DB] | [S,CH,DB] | [S,CH,DB] |\n",
    "|Hierarchical |[S,CH,DB]| [S,CH,DB]| [S,CH,DB] | [S,CH,DB]|\n",
    "|DBSCAN | X | X | X | [S,CH,DB] |\n",
    "\n",
    "\n",
    "\n",
    "### Optimality \n",
    "You will need to find the optimal k for K-means and Hierarchical algorithms.\n",
    "Find the optimality for k in the range 2 to 50.\n",
    "Provide the code used to generate the optimal k and provide justification for your approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2b033",
   "metadata": {},
   "source": [
    "|Algorithm| k = 9 | k = 18| k = 36 | Optimal k| \n",
    "|--|--|--|--|--|\n",
    "|K-means|0.018356910057666313, 1.2987109728466466, 1.8939094988332665|-0.0023270566421437957, 1.3033397792478436, 1.2575264983050891|0.008048219490464064, 1.2739460443483683, 1.0752777864394105|45|\n",
    "|Hierarchical |0.005663914856966519, 1.445434318707135, 2.8698546765571673|0.012432892332997752, 1.34875079442378, 1.8753579789793338| 0.0163241030167149, 1.3601269789601307, 1.1751112095704626|50|\n",
    "|DBSCAN | X | X | X | -- |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dc8c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "random_seed = 10086\n",
    "model_name = 'model.pkl'\n",
    "score = 0\n",
    "score_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d96d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(S, CH, DB):\n",
    "    return S * CH / DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72faeaad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6236ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(df['raw text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1948d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "(64, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "410f968b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3ddf3c73efa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "X = X.toarray()\n",
    "model = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c4713c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2, kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 45, kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\10605\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.026201491122642716, 1.7771036552226012, 1.455078777195983), (3, 0.014942185219364629, 1.5290745498451392, 4.978054831108032), (4, 0.021454649442907463, 1.5094573860361247, 4.131231656887265), (5, -0.023966016541466982, 1.2915550083782397, 2.4404393884800926), (6, 0.008583656972587788, 1.314549388652139, 2.078590402731845), (7, 0.015038645153087298, 1.363497686081285, 2.979934413769687), (8, -0.017264585713397264, 1.3097791851220084, 2.7785304800651778), (9, 0.018356910057666313, 1.2987109728466466, 1.8939094988332665), (10, 0.0018499463516662342, 1.252480692040077, 1.4053614168134638), (11, -0.014644164332172298, 1.2658937438239382, 1.58752391395445), (12, -0.018691996317524155, 1.2896184629222243, 2.3697002509177056), (13, -0.009245359846450326, 1.2870986440763648, 1.326477320298282), (14, 0.014588583195611373, 1.2389564864032778, 1.4710276374450808), (15, 0.014490174510875291, 1.2400696501558455, 1.154318990118372), (16, 0.00686902704978563, 1.2481487712448018, 1.2132704128539777), (17, 0.011897803844354581, 1.2327196959808147, 1.0568204859158472), (18, -0.0023270566421437957, 1.3033397792478436, 1.2575264983050891), (19, -0.0058153453375342275, 1.24868862887925, 1.1482072401056087), (20, -0.0008678093678169928, 1.28038549532994, 1.2925702712843237), (21, 0.011677037773352675, 1.2658966352680663, 1.064149984099728), (22, 0.019726133759091123, 1.2707624501691497, 1.0520355687896303), (23, -9.844783493566595e-05, 1.2478563615121194, 1.1909262875441429), (24, 0.014275970823377166, 1.2577334109090526, 1.1549812746501942), (25, 0.02087478410246871, 1.2476389352910695, 0.9270049243276357), (26, 0.004750429374087147, 1.2885511495934578, 1.1367593154846296), (27, 0.010954547689579935, 1.262370077516093, 1.1059435746348167), (28, 0.0208522425586804, 1.2667973704393647, 1.0111658298945043), (29, 0.02111213582979731, 1.2565833585801667, 0.9677286952912161), (30, 0.024527863307768787, 1.2865179723172988, 1.0201034871945012), (31, 0.005778702057533552, 1.289205803272043, 1.0249075580102571), (32, 0.006789301956975158, 1.2820748326702525, 1.0259841874431315), (33, 0.002883478212604299, 1.2860406478591961, 0.9800336381934063), (34, 0.01239063887857213, 1.2819522763430136, 1.118898582894101), (35, 0.020844229017896038, 1.284489283428999, 1.1515420947933253), (36, 0.008048219490464064, 1.2739460443483683, 1.0752777864394105), (37, 0.008710673188550138, 1.3008044933494445, 1.0445451870495497), (38, 0.004574461824327988, 1.2916799161413215, 1.0060386933136534), (39, 0.014525950392694031, 1.2905978601025332, 1.0088981473096037), (40, 0.013865459203001938, 1.3107595877039184, 1.0069195552828218), (41, 0.012058777061464283, 1.3131640909330522, 0.9704776486408729), (42, 0.009319218488234263, 1.3075585010745723, 1.0143019789778709), (43, 0.010294345550937297, 1.3248024415995985, 0.9336936881711665), (44, 0.017365573135690024, 1.361402542155219, 0.9419410443199948), (45, 0.02570246218795265, 1.380180246266751, 0.893727124502486), (46, 0.01935880067298813, 1.3715464551773666, 0.9432542988398972), (47, 0.012507317913552205, 1.3621866745765272, 0.904514078630088), (48, 0.01719569479772124, 1.3853534934977105, 0.9172333532067448), (49, 0.013435530845060401, 1.375566895346286, 0.8918687711508277), (50, 0.014390287235620542, 1.4110620333846355, 0.8569444084850484)]\n"
     ]
    }
   ],
   "source": [
    "k_means_scores = []\n",
    "for k in range(2, 51):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_seed)\n",
    "    kmeans_labels = kmeans.fit_predict(X)\n",
    "    kmeans_silhouette = silhouette_score(X, kmeans_labels)\n",
    "    kmeans_calinski_harabasz = calinski_harabasz_score(X, kmeans_labels)\n",
    "    kmeans_davies_bouldin = davies_bouldin_score(X, kmeans_labels)\n",
    "    k_means_scores.append((k, kmeans_silhouette, kmeans_calinski_harabasz, kmeans_davies_bouldin))\n",
    "    \n",
    "    if metric(kmeans_silhouette, kmeans_calinski_harabasz, kmeans_davies_bouldin) > score:\n",
    "        score = metric(kmeans_silhouette, kmeans_calinski_harabasz, kmeans_davies_bouldin)\n",
    "        \n",
    "        print(f'k = {k}, kmeans')\n",
    "        model = kmeans.fit(X)\n",
    "print(k_means_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e4a66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.0, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "002513d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 49, hierarchical\n",
      "k = 50, hierarchical\n",
      "[(2, 0.026201491122642716, 1.7771036552226012, 1.455078777195983), (3, 0.02655114892687444, 1.7298727277279753, 4.236972073166805), (4, 0.029815274184603963, 1.6589896305702534, 3.631355625995335), (5, 0.03180593517712997, 1.5827448279884282, 3.2626516743523966), (6, 0.032556243547474384, 1.5346609448262953, 2.8638683960226476), (7, 0.021723274007616693, 1.502275888855633, 2.7216280741680388), (8, 0.0055261584395401644, 1.4729787108120982, 3.025790996539374), (9, 0.005663914856966519, 1.445434318707135, 2.8698546765571673), (10, 0.0062969388531124125, 1.4243819726689315, 2.6550799564160616), (11, 0.007636812049384014, 1.4078186465106874, 2.3795538898994617), (12, 0.008716399478678376, 1.394604012407734, 2.4610768948395196), (13, 0.009429522169521982, 1.3833687092038005, 2.321755131265557), (14, 0.009596233085723471, 1.3736798429827193, 2.2952816682247454), (15, 0.010303226075237242, 1.3651966624852006, 2.1786743659078573), (16, 0.010354855485087227, 1.3584195365650984, 2.1137775524434277), (17, 0.011090031512829678, 1.3529098124367278, 2.007915835491125), (18, 0.012432892332997752, 1.34875079442378, 1.8753579789793338), (19, 0.013810570017185931, 1.3458551001751375, 1.7565631362983567), (20, 0.015091941461548773, 1.34274805790164, 1.6506319236555367), (21, 0.01544208324551231, 1.340466863044517, 1.6626882737487296), (22, 0.0027460247614320074, 1.3388098007072098, 1.6600154168526082), (23, 0.003989623271357359, 1.3375703060219064, 1.6027769219901529), (24, 0.004736240330232215, 1.336268808340398, 1.562435796505059), (25, 0.0055907911571772455, 1.3356435851714175, 1.5232828236826474), (26, 0.006525396778155422, 1.3357868447887555, 1.4810942741944946), (27, 0.007429275468273047, 1.3361420489298832, 1.4444597913267625), (28, 0.008621220990111936, 1.3372795576543903, 1.4049345487239933), (29, 0.009459727834707634, 1.3385383929392907, 1.3743918542464306), (30, 0.010401273045478006, 1.3404881727995435, 1.343463037195432), (31, 0.011519272486613472, 1.3425315052378555, 1.3194010579493634), (32, 0.01220714794222514, 1.3452610348672431, 1.2886627508777484), (33, 0.01377023911817215, 1.3482490992705536, 1.2389136057804642), (34, 0.014567199626531873, 1.3519634019221292, 1.2202201810517814), (35, 0.015515804807480979, 1.3561623485788301, 1.1905719082826143), (36, 0.0163241030167149, 1.3601269789601307, 1.1751112095704626), (37, 0.017233001743884667, 1.364250495646886, 1.1607867866958188), (38, 0.017938125343709616, 1.368832112099272, 1.1474818305494228), (39, 0.018673108832932845, 1.3735487749843143, 1.1161903566503621), (40, 0.019401974423968026, 1.3791731355061294, 1.10320240783178), (41, 0.02015790280825248, 1.3854351810325114, 1.0876247889735542), (42, 0.02038305816031737, 1.3920907584744273, 1.0894392055301985), (43, 0.020805965759036527, 1.400049366142463, 1.0533783175519482), (44, 0.020332214007981537, 1.4094155990644752, 1.0245159227201674), (45, 0.020875731085406697, 1.4201321066980015, 1.0082152918575433), (46, 0.022380446402819304, 1.432911433662645, 0.9786147346529432), (47, 0.023133726003238816, 1.4479029387602733, 0.943806817870545), (48, 0.024121312147267558, 1.4642137449248596, 0.9172212481862103), (49, 0.025537220834258974, 1.4827579581408123, 0.8917452698807664), (50, 0.02626570579773628, 1.502911577772275, 0.8767248459099851)]\n"
     ]
    }
   ],
   "source": [
    "hierarchical_scores = []\n",
    "for k in range(2, 51):\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=k)\n",
    "    hierarchical_labels = hierarchical.fit_predict(X)\n",
    "    hierarchical_silhouette = silhouette_score(X, hierarchical_labels)\n",
    "    hierarchical_calinski_harabasz = calinski_harabasz_score(X, hierarchical_labels)\n",
    "    hierarchical_davies_bouldin = davies_bouldin_score(X, hierarchical_labels)\n",
    "    hierarchical_scores.append((k, hierarchical_silhouette, hierarchical_calinski_harabasz, hierarchical_davies_bouldin))\n",
    "    \n",
    "    if metric(hierarchical_silhouette, hierarchical_calinski_harabasz, hierarchical_davies_bouldin) > score:\n",
    "        score = metric(hierarchical_silhouette, hierarchical_calinski_harabasz, hierarchical_davies_bouldin)\n",
    "        print(f'k = {k}, hierarchical')\n",
    "        model = hierarchical.fit(X)\n",
    "        \n",
    "print(hierarchical_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20fd69",
   "metadata": {},
   "source": [
    "#### How did you approach finding the optimal k?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c54da",
   "metadata": {},
   "source": [
    "[Your answer here]50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ec635",
   "metadata": {},
   "source": [
    "#### What algorithm do you believe is the best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136b0a4",
   "metadata": {},
   "source": [
    "[Your Answer]hierarchical, it is the result we run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45a2a3",
   "metadata": {},
   "source": [
    "### Add Cluster ID to output file\n",
    "In your data structure, add the cluster id for each smart city respectively. Show the to append the clusterid code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ad83e3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.cluster._agglomerative.AgglomerativeClustering'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AgglomerativeClustering' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b9f19b9df8ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4133\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4134\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4135\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-b9f19b9df8ea>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AgglomerativeClustering' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "df['cluster_id'] = df['clean text'].apply(lambda x : model.predict(tfidf_vectorizer.fit_transform([x]).toarray())[0])\n",
    "print(df['cluster_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e7275",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "After finding the best model, it is desirable to have a way to persist the model for future use without having to retrain. Save the model using [model persistance](https://scikit-learn.org/stable/model_persistence.html). This model should be saved in the same directory as this notebook and should be loaded as the model for your `project3.py`.\n",
    "\n",
    "Save the model as `model.pkl`. You do not have to use pickle, but be sure to save the persistance using one of the methods listed in the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(model_name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe5a0c9",
   "metadata": {},
   "source": [
    "## Derving Themes and Concepts (Required)\n",
    "\n",
    "Perform Topic Modeling on the cleaned data. Provide the top five words for `TOPIC_NUM = Best_k` as defined in the section above. Feel free to reference [Chapter 6](https://github.com/dipanjanS/text-analytics-with-python/tree/master/New-Second-Edition/Ch06%20-%20Text%20Summarization%20and%20Topic%20Models) for more information on Topic Modeling and Summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b684bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "915516dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,2),\n",
    "                     token_pattern=None, tokenizer=lambda doc: doc,\n",
    "                     preprocessor=lambda doc: doc)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['text'] = df['raw text'].apply(lambda x : x.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a2a3896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ce41d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def get_topic(text):\n",
    "    strs = text.split('\\n')\n",
    "    norm_strs = normalize_corpus(strs)\n",
    "    cv = CountVectorizer(ngram_range=(1,2),\n",
    "                     token_pattern=None, tokenizer=lambda doc: doc,\n",
    "                     preprocessor=lambda doc: doc)\n",
    "    cv_features = cv.fit_transform(norm_strs)\n",
    "    \n",
    "    vocabulary = np.array(cv.get_feature_names())\n",
    "    lsi_model = TruncatedSVD(n_components=50, n_iter=50, random_state=42)\n",
    "    document_topics = lsi_model.fit_transform(cv_features)\n",
    "    topic_terms = lsi_model.components_\n",
    "    \n",
    "    top_terms = 2\n",
    "    topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "    topic_keyterm_weights = np.array([topic_terms[row, columns] \n",
    "                                 for row, columns in list(zip(np.arange(50), topic_key_term_idxs))])\n",
    "    topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "    topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "    for n in range(2):\n",
    "        d1 = []\n",
    "        d2 = []\n",
    "        terms, weights = topic_keyterms_weights[n]\n",
    "        term_weights = sorted([(t, w) for t, w in zip(terms, weights)], \n",
    "                              key=lambda row: -abs(row[1]))\n",
    "        for term, wt in term_weights:\n",
    "            if wt >= 0:\n",
    "                d1.append((term, round(wt, 3)))\n",
    "            else:\n",
    "                d2.append((term, round(wt, 3)))\n",
    "\n",
    "    return [d1, d2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ea855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1573fe65",
   "metadata": {},
   "source": [
    "### Extract themes\n",
    "Write a theme for each topic (atleast a sentence each)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737d8df",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf24c6",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e191f4",
   "metadata": {},
   "source": [
    "[Your Answer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab7df0",
   "metadata": {},
   "source": [
    "### Add Topid ID to output file\n",
    "Add the top two topics for each smart city to the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e937841",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'feature_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-0541d101db3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topicids'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mget_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4133\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4134\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4135\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-94-0541d101db3f>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'topicids'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mget_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-93-eaea97352fad>\u001b[0m in \u001b[0;36mget_topic\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcv_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_strs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mlsi_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdocument_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsi_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'feature_name'"
     ]
    }
   ],
   "source": [
    "df['topicids'] = df['clean text'].apply(lambda x : get_topic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e568652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f9c240",
   "metadata": {},
   "source": [
    "## Gathering Applicant Summaries and Keywords (Extra Credit Section)\n",
    "\n",
    "For each smart city applicant, gather a summary and keywords that are important to that document. Gensim is outdated; try a spacy or nltk method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86cbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the funciton is in project3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b545ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d27ce37",
   "metadata": {},
   "source": [
    "### Add Summaries and Keywords\n",
    "Add summary and keywords to output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09357ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keywords'] = df['raw text'].apply(lambda x : summarize(x)[0])\n",
    "df['summary'] = df['raw text'].apply(lambda x : summarize(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cb2c4",
   "metadata": {},
   "source": [
    "## Write output data (Required)\n",
    "\n",
    "The output data should be written as a TSV file.\n",
    "You can use `to_csv` method from Pandas for this if you are using a DataFrame.\n",
    "\n",
    "`Syntax: df.to_csv('file.tsv', sep = '')` \\\n",
    "`df.to_csv('smartcity_eda.tsv', sep='\\t')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58827464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('smartcity_eda.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18b8ff",
   "metadata": {},
   "source": [
    "# Moving Forward\n",
    "Now that you have explored the dataset, take the important features and functions to create your `project3.py`.\n",
    "Please refer to the project spec for more guidance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6675ba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
